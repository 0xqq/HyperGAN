        if config['conv_g_layers']:
            if(config['g_strategy'] == 'phase'):
                chans = 4*4*3
                result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_'+str(i), output_channels=chans, noise_shape=result.get_shape())
                result = PS(result, 4, color=True)

            elif(config['g_strategy'] == 'resize-conv'):

  
            elif(config['g_strategy'] == 'deconv-phase'):
                print("__RES",result)
                for i in range(4):
                    s = [int(x) for x in result.get_shape()]
                    layers = int(result.get_shape()[3])+1024
                    s[-1]=layers//4
                    if(s[-1] == 0):
                         s[-1]=1
                    #result = block_deconv(result, activation, batch_size, 'deconv', 'g_layers_'+str(i), output_channels=int(result.get_shape()[3])+layers, noise_shape=s)
                    result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_'+str(i), output_channels=layers, noise_shape=s, filter=1)
                    size = int(result.get_shape()[1])*int(result.get_shape()[2])*int(result.get_shape()[3])
                    print("g at i ",i, result, size, 128*128*12)

                result = tf.depth_to_space(result, 32)
                noise_shape = [int(x) for x in result.get_shape()]
                noise_shape[-1]=1
                result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_end3', output_channels=2*2*3, noise_shape=noise_shape, filter=3)
                print("before phase shift", result)
                result = PS(result, 2, color=True)
                print("after phase shift", result)
 
            elif(config['g_strategy'] == 'wide-deconv-phase'):
                print("__RES",result)
                for i in range(4):
                    s = [int(x) for x in result.get_shape()]
                    layers = int(result.get_shape()[3])*2
                    noise = [s[0],s[1],s[2],2**(5-i)]
                    result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_'+str(i), output_channels=layers, filter=3, noise_shape=noise)
                    size = int(result.get_shape()[1])*int(result.get_shape()[2])*int(result.get_shape()[3])
                    print("g at i ",i, result, size, 512*382*3)

                result = tf.depth_to_space(result, 16)
                noise_shape = [int(x) for x in result.get_shape()]
                noise_shape[-1]=1
                result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_end3', output_channels=2*2*3, noise_shape=noise_shape, filter=3)
                print("before phase shift", result)
                result = PS(result, 2, color=True)
                print("after phase shift", result)
 
            elif(config['g_strategy'] == 'conv-phase'):
                chans = 16*16*3
                print("1RESULT", result)
                noise_shape = [int(x) for x in result.get_shape()]
                noise_shape[-1]=8
                result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_1', output_channels=result.get_shape()[3]*2)
                result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_2', output_channels=result.get_shape()[3]*2)
                print("2.2RESULT", result)
                result = block_deconv(result, activation, batch_size, 'identity', 'g_layers_end', output_channels=chans)
                print("5RESULT", result)
                result = PS(result, 16, color=True)
 

            elif(config['g_strategy'] == 'conv-depth-to-space'):
                widenings = 6
                stride = 2
                zs = [None]
                h = int(result.get_shape()[1])
                w = int(result.get_shape()[2])
                for i in range(widenings):
                    if(i==widenings-1):
                        result = block_conv_dts(result, activation, batch_size, 'end', 'g_layers_'+str(i), output_channels=config['channels'], stride=stride)
                    else:
                        result = block_conv_dts(result, activation, batch_size, 'conv', 'g_layers_'+str(i), stride=stride)
                    print("SIZE IS" ,result)
  

            elif(config['g_strategy'] == 'small-skip'):
                widenings = 6
                stride = 2
                zs = [None]
                h = int(result.get_shape()[1])
                w = int(result.get_shape()[2])
                sc_layers = config['g_skip_connections_layers']
                for i in range(widenings-1):
                    w*=stride
                    h*=stride
                    size = w*h*int(sc_layers[i])
                    print("original z", original_z, size)
                    if(size != 0):
                        new_z = tf.random_uniform([config['batch_size'], size],-1, 1,dtype=config['dtype'])
                        print('new_z', new_z)
                        #new_z = linear(new_z, size, scope='g_skip_z_'+str(i))
                        new_z = tf.reshape(new_z, [config['batch_size'], h,w, sc_layers[i]])

                        zs.append(new_z)
                for i in range(widenings):
                    print("BEFORE SIZE IS" ,result)
                    if(config['g_skip_connections'] and i!=0 and i < len(zs)):
                        result = tf.concat(3, [result, zs[i]])
                    if(i==widenings-1):
                        result = block_deconv(result, activation, batch_size, 'deconv', 'g_layers_'+str(i), output_channels=config['channels'], stride=stride)
                    else:
                        result = block_deconv(result, activation, batch_size, 'deconv', 'g_layers_'+str(i), stride=stride)
                    print("SIZE IS" ,result)
  
            elif(config['g_strategy'] == 'wide-resnet'):
                #result = residual_block_deconv(result, activation, batch_size, 'widen', 'g_layers_p')
                #result = residual_block_deconv(result, activation, batch_size, 'identity', 'g_layers_i1')
                widenings = 6
                stride = 2
                zs = [None]
                h = int(result.get_shape()[1])
                w = int(result.get_shape()[2])
                sc_layers = config['g_skip_connections_layers']
                for i in range(widenings-1):
                    w*=stride
                    h*=stride
                    size = w*h*int(sc_layers[i])
                    print("original z", original_z, size)
                    if(size != 0):
                        new_z = tf.random_uniform([config['batch_size'], size],-1, 1,dtype=config['dtype'])
                        print('new_z', new_z)
                        #new_z = linear(new_z, size, scope='g_skip_z_'+str(i))
                        new_z = tf.reshape(new_z, [config['batch_size'], h,w, sc_layers[i]])

                        zs.append(new_z)
                for i in range(widenings):
                    print("BEFORE SIZE IS" ,result)
                    if(config['g_skip_connections'] and i!=0 and i < len(zs)):
                        result = tf.concat(3, [result, zs[i]])
                    if(i==widenings-1):
                        result = residual_block_deconv(result, activation, batch_size, 'deconv', 'g_layers_'+str(i), output_channels=config['channels']+13, stride=stride)
                        result = residual_block_deconv(result, activation, batch_size, 'bottleneck', 'g_layers_bottleneck_'+str(i), channels=config['channels'])
                        #result = residual_block_deconv(result, activation, batch_size, 'identity', 'g_layers_i_'+str(i))
                    else:
                        result = residual_block_deconv(result, activation, batch_size, 'deconv', 'g_layers_'+str(i), stride=stride)
                        result = residual_block_deconv(result, activation, batch_size, 'identity', 'g_layers_i_'+str(i))
                    print("SIZE IS" ,result)
                #result = tf.reshape(result,[config['batch_size'],x_dims[0],x_dims[1],-1])
                #result = batch_norm(batch_size, name='g_rescap_bn')(result)
                #result = activation(result)
                #result = conv2d(result, config['channels'], name='g_grow', k_w=3,k_h=3, d_h=1, d_w=1)
                #result = tf.slice(result, [0,0,0,0],[config['batch_size'], x_dims[0],x_dims[1],config['channels']])
                #print("END SIZE IS", result)
                #stride = x_dims[0]//int(result.get_shape()[1])
                #result = build_deconv_tower(result, [output_channels], x_dims, stride+1, 'g_conv_2', config['g_activation'], config['g_batch_norm'], config['g_batch_norm_last_layer'], config['batch_size'], config['g_last_layer_stddev'], stride=stride)
            elif(config['g_strategy'] == 'huge_deconv'):
                result = batch_norm(config['batch_size'], name='g_bn_lin_proj')(result)
                result = config['g_activation'](result)
                result = build_resnet(result, config['g_resnet_depth'], config['g_resnet_filter'], 'g_conv_res_', config['g_activation'], config['batch_size'], config['g_batch_norm'])
                result = build_deconv_tower(result, config['conv_g_layers'][1:2]+[output_channels], x_dims, config['g_huge_filter'], 'g_conv_2', config['g_activation'], config['g_batch_norm'], config['g_batch_norm_last_layer'], config['batch_size'], config['g_last_layer_stddev'], stride=config['g_huge_stride'])
            elif(config['g_strategy'] == 'deep_deconv'):
                result = batch_norm(config['batch_size'], name='g_bn_lin_proj')(result)
                result = config['g_activation'](result)
                result = build_deconv_tower(result, config['conv_g_layers'][1:2], x_dims, config['conv_size'], 'g_conv_', config['g_activation'], config['g_batch_norm'], True, config['batch_size'], config['g_last_layer_stddev'])
                result = config['g_activation'](result)
                result = build_resnet(result, config['g_resnet_depth'], config['g_resnet_filter'], 'g_conv_res_', config['g_activation'], config['batch_size'], config['g_batch_norm'])
                result = build_deconv_tower(result, config['conv_g_layers'][2:-1]+[output_channels], x_dims, config['g_post_res_filter'], 'g_conv_2', config['g_activation'], config['g_batch_norm'], config['g_batch_norm_last_layer'], config['batch_size'], config['g_last_layer_stddev'])


        if(config['include_f_in_d']):
            rs = [int(s) for s in result.get_shape()]
            result1 = tf.slice(result,[0,0,0,0],[config['batch_size'], rs[1],rs[2],3])
            result2 = tf.slice(result,[0,0,0,3],[config['batch_size'], rs[1],rs[2],1])
            result1 = config['g_last_layer'](result1)
            result2 = batch_norm(config['batch_size'], name='g_bn_relu_f')(result2)
            result2 = tf.nn.relu(result2)
            result = tf.concat(3, [result1, result2])
        elif(config['g_last_layer']):
            result = config['g_last_layer'](result)


